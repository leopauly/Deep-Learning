{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Program used for studying how to systematically record results by using CSVLogger, exporting model to a json file, exporting \n",
    "# weights in Hd5 format, using time stamps, using text files to store stdout etc.\n",
    "# created by @leopauly (cnlp@leeds.ac.uk)\n",
    "\n",
    "import numpy\n",
    "import datetime\n",
    "import glob\n",
    "import sys\n",
    "from PIL import Image  \n",
    "from scipy import misc\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import History,CSVLogger \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#imageFolderPath = './allnew/'\n",
    "#imagePath = glob.glob(imageFolderPath+'/*.jpg') \n",
    "#X = numpy.array([numpy.array((Image.open(imagePath[i]).convert('L')), 'f') for i in range(len(imagePath))] )\n",
    "#print (X.shape)\n",
    "#img_rows=32\n",
    "#img_cols=32\n",
    "#channel=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y_1=numpy.ones(13233)\n",
    "#y_2=numpy.zeros(7390)\n",
    "#y=numpy.append(y_1,y_2)\n",
    "#nb_classes=1\n",
    "#print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X,y = shuffle(X,y, random_state=1)\n",
    "#X,y = shuffle(X,y, random_state=2)\n",
    "#X,y = shuffle(X,y, random_state=3)\n",
    "#X,y = shuffle(X,y, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('th')\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "img_rows=32\n",
    "img_cols=32\n",
    "channel=3\n",
    "nb_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n",
      "(10000, 3, 32, 32)\n",
      "(50000, 3, 32, 32)\n",
      "(10000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "X_train = X_train.reshape(X_train.shape[0], channel,img_rows, img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], channel,img_rows, img_cols)\n",
    "input_shape=(channel,img_rows,img_cols)\n",
    "\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255.\n",
    "X_test /= 255.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(16, 3, 3, input_shape=input_shape, activation='relu',border_mode='valid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu', border_mode='valid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', W_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 16, 30, 30)    448         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 16, 30, 30)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 32, 28, 28)    4640        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 32, 28, 28)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 32, 14, 14)    0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 6272)          0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 256)           1605888     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 256)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 10)            2570        dropout_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1613546\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-02-09 13:53:11.448770\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 63s - loss: 2.1310 - acc: 0.2061 - val_loss: 2.0905 - val_acc: 0.2850\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 50s - loss: 1.9439 - acc: 0.3004 - val_loss: 1.9826 - val_acc: 0.3526\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 50s - loss: 1.8457 - acc: 0.3437 - val_loss: 1.9026 - val_acc: 0.3818\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 50s - loss: 1.7811 - acc: 0.3649 - val_loss: 1.8594 - val_acc: 0.4040\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 50s - loss: 1.7227 - acc: 0.3867 - val_loss: 1.7921 - val_acc: 0.4237\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 50s - loss: 1.6718 - acc: 0.4043 - val_loss: 1.7369 - val_acc: 0.4426\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 49s - loss: 1.6170 - acc: 0.4214 - val_loss: 1.6848 - val_acc: 0.4624\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 50s - loss: 1.5723 - acc: 0.4366 - val_loss: 1.6466 - val_acc: 0.4661\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 51s - loss: 1.5319 - acc: 0.4501 - val_loss: 1.6108 - val_acc: 0.4787\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 52s - loss: 1.5035 - acc: 0.4634 - val_loss: 1.5856 - val_acc: 0.4879\n",
      "2017-02-09 14:01:50.552113\n"
     ]
    }
   ],
   "source": [
    "b_size=128\n",
    "#csv_logger = CSVLogger('trainingcnn4.log',separator=',', append=True)\n",
    "\n",
    "start_time=datetime.datetime.now()\n",
    "print (start_time)\n",
    "\n",
    "history=model.fit(X_train, y_train, nb_epoch=epochs, \n",
    "                  batch_size=b_size, validation_split=0.2, \n",
    "                  shuffle='batch')\n",
    "\n",
    "end_time=datetime.datetime.now()\n",
    "print (end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 49.54%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#storing model to a json file and weights in HDF5 format\n",
    "\n",
    "model_json = model.to_json()\n",
    "# saving model\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5 and saving it\n",
    "model.save_weights(\"model.txt\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "# load json file and load the model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#attempt to store model and weights to a simple text file\n",
    "#Preparing documentation\n",
    "\n",
    "sys.stdout = open('resultslog.txt', 'a')\n",
    "\n",
    "print(\"\\n\",'LeedsNet <Attempt 3> : Results when LeedsNet was trained using MNIST dataset',\"\\n\")\n",
    "print(\"\\n\",'Network architechture',\"\\n\")\n",
    "print(model.summary())\n",
    "print(\"\\n\",'Results: Training',\"\\n\",history.history,\"\\n\")\n",
    "print(\"\\n\",'Time taken for training',\"\\n\",' Start Time:', start_time,\"\\n\",'End Time:', end_time,\"\\n\")\n",
    "print(\"\\n\",\"Accuracy on testing data: %.2f%%\" % (scores[1]*100),\"\\n\")\n",
    "\n",
    "sys.stdout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
